We've split our project into two groups, one working on training the AI for gesture recognition and one to configure the output given to us by the AI into a usable form on a windows device.

For the output configuration, we've identified a python library that will allow us to manipulate keypresses and mouse movement
https://pypi.org/project/pynput/

While we have had progress working with lambda labs and figuring out how it will function with our project, mid-terms have presented a significant obstacle as far as time management goes, but this should rectify itself as exams finish up.

Going forward into the next few weeks our main goal will getting the AI working so we can start to integrate the AI with the python libraries.
